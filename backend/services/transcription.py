"""
Speech-to-Text Transcription Service

Uses Faster Whisper to transcribe speech audio.
"""

import numpy as np
import logging
import io  # For BytesIO
from typing import Dict, Any, List, Optional, Tuple
from faster_whisper import WhisperModel
import time
import torch  # For CUDA availability check

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class WhisperTranscriber:
    """
    Speech-to-Text service using Faster Whisper.

    This class handles transcription of speech audio segments.
    """

    def __init__(
        self,
        model_size: str = "base",
        device: str = None,
        compute_type: str = None,
        beam_size: int = 2,
        sample_rate: int = 44100,
    ):
        """
        Initialize the transcription service.

        Args:
            model_size: Whisper model size (tiny.en, base.en, small.en, medium.en, large)
            device: Device to run model on ('cpu' or 'cuda'), if None will auto-detect
            compute_type: Model computation type (int8, int16, float16, float32), if None will select based on device
            beam_size: Beam size for decoding
            sample_rate: Audio sample rate in Hz
        """
        self.model_size = model_size

        # Auto-detect device if not specified
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device

        # Select appropriate compute type based on device if not specified
        if compute_type is None:
            self.compute_type = "float16" if self.device == "cuda" else "int8"
        else:
            self.compute_type = compute_type

        self.beam_size = beam_size
        self.sample_rate = sample_rate

        # Initialize model
        self._initialize_model()

        # State tracking
        self.is_processing = False

        logger.info(
            f"Initialized Whisper Transcriber with model={model_size}, "
            f"device={self.device}, compute_type={self.compute_type}"
        )

    def _initialize_model(self):
        """Initialize Whisper model."""
        try:
            # Load the model
            self.model = WhisperModel(
                self.model_size,  # Pass as positional argument, not keyword
                device=self.device,
                compute_type=self.compute_type,
            )
            logger.info(f"Successfully loaded Whisper model: {self.model_size}")
        except Exception as e:
            logger.error(f"Failed to load Whisper model: {e}")
            raise

    def transcribe(self, audio: np.ndarray) -> Tuple[str, Dict[str, Any]]:
        """
        Transcribe audio data to text.

        Args:
            audio: Audio data as numpy array

        Returns:
            Tuple[str, Dict[str, Any]]:
                - Transcribed text
                - Dictionary with additional information (confidence, language, etc.)
        """
        start_time = time.time()
        self.is_processing = True

        try:
            # Handle WAV data (if audio is in uint8 format, it contains WAV headers)
            if audio.dtype == np.uint8:
                # First check the RIFF header to confirm this is WAV data
                header = bytes(audio[:44])
                if header[:4] == b"RIFF" and header[8:12] == b"WAVE":
                    # Create a file-like object that Whisper can read from
                    audio_file = io.BytesIO(bytes(audio))
                    # The transcribe method expects a file-like object with read method
                    audio = audio_file
                else:
                    # Not a proper WAV header
                    logger.warning("Received audio data with incorrect WAV header")
                    # Attempt to process as raw data
                    audio = (
                        audio.astype(np.float32) / np.max(np.abs(audio))
                        if np.max(np.abs(audio)) > 0
                        else audio
                    )
            else:
                # Normalize audio if it's raw float data
                audio = (
                    audio.astype(np.float32) / np.max(np.abs(audio))
                    if np.max(np.abs(audio)) > 0
                    else audio
                )

            # Transcribe
            segments, info = self.model.transcribe(
                audio,
                beam_size=self.beam_size,
                language="en",  # Force English language
                vad_filter=False,  # Disable VAD filter since we handle it in the frontend
            )

            # Collect all segment texts
            text_segments = [segment.text for segment in segments]
            full_text = " ".join(text_segments).strip()

            # Calculate processing time
            processing_time = time.time() - start_time
            logger.info(
                f"Transcription completed in {processing_time:.2f}s: {full_text[:50]}..."
            )

            metadata = {
                "confidence": getattr(info, "avg_logprob", 0),
                "language": getattr(info, "language", "en"),
                "processing_time": processing_time,
                "segments_count": len(text_segments),
            }

            return full_text, metadata

        except Exception as e:
            logger.error(f"Transcription error: {e}")
            return "", {"error": str(e)}
        finally:
            self.is_processing = False

    def transcribe_streaming(self, audio_generator):
        """
        Stream transcription results from an audio generator.

        Args:
            audio_generator: Generator yielding audio chunks

        Yields:
            Partial transcription results as they become available
        """
        self.is_processing = True

        try:
            # Process the streaming transcription
            segments = self.model.transcribe_with_vad(audio_generator, language="en")

            # Yield each segment as it's transcribed
            for segment in segments:
                yield {
                    "text": segment.text,
                    "start": segment.start,
                    "end": segment.end,
                    "confidence": segment.avg_logprob,
                }

        except Exception as e:
            logger.error(f"Streaming transcription error: {e}")
            yield {"error": str(e)}
        finally:
            self.is_processing = False

    def get_config(self) -> Dict[str, Any]:
        """
        Get the current configuration.

        Returns:
            Dict containing the current configuration
        """
        return {
            "model_size": self.model_size,
            "device": self.device,
            "compute_type": self.compute_type,
            "beam_size": self.beam_size,
            "sample_rate": self.sample_rate,
            "is_processing": self.is_processing,
        }

    def reset_state(self) -> None:
        """
        Forcibly reset the transcription service state.

        This is useful when operations need to be interrupted immediately,
        such as when the user sends an interrupt command.
        """
        self.is_processing = False
        logger.info("Transcription service state forcibly reset")
